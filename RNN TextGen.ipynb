{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Dense,Dropout,LSTM,CuDNNLSTM\n",
    "import seaborn as sns\n"
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"Harrytest.txt\"\n",
    "raw_text = open(\"D:/TextRNN/{}\".format(filename)).read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "chars_to_int = dict((c,i) for i,c in enumerate(chars))
    #sldkh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '\\\\', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '~', '»', '¿', 'â', 'ï', 'œ', '“', '€']\n"
     ]
    }
   ],
   "source": [
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters: 442771\n",
      "Total Vocab: 59\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "\n",
    "print(\"Total Characters: {}\".format(n_chars))\n",
    "print(\"Total Vocab: {}\".format(n_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns: 442671\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i : i+seq_length]\n",
    "    seq_out = raw_text[i+seq_length]\n",
    "    dataX.append([chars_to_int[char] for char in seq_in])\n",
    "    dataY.append(chars_to_int[seq_out])\n",
    "    \n",
    "n_patterns = len(dataX)\n",
    "print (\"Total Patterns: {}\".format(n_patterns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55, 52, 53, 32, 25, 42, 42, 49, 1, 40, 39, 44, 44, 29, 42, 1, 25, 38, 28, 1, 44, 32, 29, 1, 43, 39, 42, 27, 29, 42, 29, 42, 4, 43, 1, 43, 44, 39, 38, 29, 1, 0, 0, 27, 32, 25, 40, 44, 29, 42, 1, 39, 38, 29, 1, 0, 0, 44, 32, 29, 1, 26, 39, 49, 1, 47, 32, 39, 1, 36, 33, 46, 29, 28, 1, 0, 0, 37, 42, 10, 1, 25, 38, 28, 1, 37, 42, 43, 10, 1, 28, 45, 42, 43, 36, 29, 49, 8, 1, 39], [52, 53, 32, 25, 42, 42, 49, 1, 40, 39, 44, 44, 29, 42, 1, 25, 38, 28, 1, 44, 32, 29, 1, 43, 39, 42, 27, 29, 42, 29, 42, 4, 43, 1, 43, 44, 39, 38, 29, 1, 0, 0, 27, 32, 25, 40, 44, 29, 42, 1, 39, 38, 29, 1, 0, 0, 44, 32, 29, 1, 26, 39, 49, 1, 47, 32, 39, 1, 36, 33, 46, 29, 28, 1, 0, 0, 37, 42, 10, 1, 25, 38, 28, 1, 37, 42, 43, 10, 1, 28, 45, 42, 43, 36, 29, 49, 8, 1, 39, 30]]\n",
      "[30, 1, 38, 45, 37, 26, 29, 42, 1, 30]\n"
     ]
    }
   ],
   "source": [
    "print(dataX[:2])\n",
    "print(dataY[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(dataX, (n_patterns, seq_length, 1)) #reshape\n",
    "X = X/float(n_vocab)\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.93220339]\n",
      "  [0.88135593]\n",
      "  [0.89830508]\n",
      "  [0.54237288]\n",
      "  [0.42372881]\n",
      "  [0.71186441]\n",
      "  [0.71186441]\n",
      "  [0.83050847]\n",
      "  [0.01694915]\n",
      "  [0.6779661 ]\n",
      "  [0.66101695]\n",
      "  [0.74576271]\n",
      "  [0.74576271]\n",
      "  [0.49152542]\n",
      "  [0.71186441]\n",
      "  [0.01694915]\n",
      "  [0.42372881]\n",
      "  [0.6440678 ]\n",
      "  [0.47457627]\n",
      "  [0.01694915]\n",
      "  [0.74576271]\n",
      "  [0.54237288]\n",
      "  [0.49152542]\n",
      "  [0.01694915]\n",
      "  [0.72881356]\n",
      "  [0.66101695]\n",
      "  [0.71186441]\n",
      "  [0.45762712]\n",
      "  [0.49152542]\n",
      "  [0.71186441]\n",
      "  [0.49152542]\n",
      "  [0.71186441]\n",
      "  [0.06779661]\n",
      "  [0.72881356]\n",
      "  [0.01694915]\n",
      "  [0.72881356]\n",
      "  [0.74576271]\n",
      "  [0.66101695]\n",
      "  [0.6440678 ]\n",
      "  [0.49152542]\n",
      "  [0.01694915]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.45762712]\n",
      "  [0.54237288]\n",
      "  [0.42372881]\n",
      "  [0.6779661 ]\n",
      "  [0.74576271]\n",
      "  [0.49152542]\n",
      "  [0.71186441]\n",
      "  [0.01694915]\n",
      "  [0.66101695]\n",
      "  [0.6440678 ]\n",
      "  [0.49152542]\n",
      "  [0.01694915]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.74576271]\n",
      "  [0.54237288]\n",
      "  [0.49152542]\n",
      "  [0.01694915]\n",
      "  [0.44067797]\n",
      "  [0.66101695]\n",
      "  [0.83050847]\n",
      "  [0.01694915]\n",
      "  [0.79661017]\n",
      "  [0.54237288]\n",
      "  [0.66101695]\n",
      "  [0.01694915]\n",
      "  [0.61016949]\n",
      "  [0.55932203]\n",
      "  [0.77966102]\n",
      "  [0.49152542]\n",
      "  [0.47457627]\n",
      "  [0.01694915]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.62711864]\n",
      "  [0.71186441]\n",
      "  [0.16949153]\n",
      "  [0.01694915]\n",
      "  [0.42372881]\n",
      "  [0.6440678 ]\n",
      "  [0.47457627]\n",
      "  [0.01694915]\n",
      "  [0.62711864]\n",
      "  [0.71186441]\n",
      "  [0.72881356]\n",
      "  [0.16949153]\n",
      "  [0.01694915]\n",
      "  [0.47457627]\n",
      "  [0.76271186]\n",
      "  [0.71186441]\n",
      "  [0.72881356]\n",
      "  [0.61016949]\n",
      "  [0.49152542]\n",
      "  [0.83050847]\n",
      "  [0.13559322]\n",
      "  [0.01694915]\n",
      "  [0.66101695]]\n",
      "\n",
      " [[0.88135593]\n",
      "  [0.89830508]\n",
      "  [0.54237288]\n",
      "  [0.42372881]\n",
      "  [0.71186441]\n",
      "  [0.71186441]\n",
      "  [0.83050847]\n",
      "  [0.01694915]\n",
      "  [0.6779661 ]\n",
      "  [0.66101695]\n",
      "  [0.74576271]\n",
      "  [0.74576271]\n",
      "  [0.49152542]\n",
      "  [0.71186441]\n",
      "  [0.01694915]\n",
      "  [0.42372881]\n",
      "  [0.6440678 ]\n",
      "  [0.47457627]\n",
      "  [0.01694915]\n",
      "  [0.74576271]\n",
      "  [0.54237288]\n",
      "  [0.49152542]\n",
      "  [0.01694915]\n",
      "  [0.72881356]\n",
      "  [0.66101695]\n",
      "  [0.71186441]\n",
      "  [0.45762712]\n",
      "  [0.49152542]\n",
      "  [0.71186441]\n",
      "  [0.49152542]\n",
      "  [0.71186441]\n",
      "  [0.06779661]\n",
      "  [0.72881356]\n",
      "  [0.01694915]\n",
      "  [0.72881356]\n",
      "  [0.74576271]\n",
      "  [0.66101695]\n",
      "  [0.6440678 ]\n",
      "  [0.49152542]\n",
      "  [0.01694915]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.45762712]\n",
      "  [0.54237288]\n",
      "  [0.42372881]\n",
      "  [0.6779661 ]\n",
      "  [0.74576271]\n",
      "  [0.49152542]\n",
      "  [0.71186441]\n",
      "  [0.01694915]\n",
      "  [0.66101695]\n",
      "  [0.6440678 ]\n",
      "  [0.49152542]\n",
      "  [0.01694915]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.74576271]\n",
      "  [0.54237288]\n",
      "  [0.49152542]\n",
      "  [0.01694915]\n",
      "  [0.44067797]\n",
      "  [0.66101695]\n",
      "  [0.83050847]\n",
      "  [0.01694915]\n",
      "  [0.79661017]\n",
      "  [0.54237288]\n",
      "  [0.66101695]\n",
      "  [0.01694915]\n",
      "  [0.61016949]\n",
      "  [0.55932203]\n",
      "  [0.77966102]\n",
      "  [0.49152542]\n",
      "  [0.47457627]\n",
      "  [0.01694915]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.62711864]\n",
      "  [0.71186441]\n",
      "  [0.16949153]\n",
      "  [0.01694915]\n",
      "  [0.42372881]\n",
      "  [0.6440678 ]\n",
      "  [0.47457627]\n",
      "  [0.01694915]\n",
      "  [0.62711864]\n",
      "  [0.71186441]\n",
      "  [0.72881356]\n",
      "  [0.16949153]\n",
      "  [0.01694915]\n",
      "  [0.47457627]\n",
      "  [0.76271186]\n",
      "  [0.71186441]\n",
      "  [0.72881356]\n",
      "  [0.61016949]\n",
      "  [0.49152542]\n",
      "  [0.83050847]\n",
      "  [0.13559322]\n",
      "  [0.01694915]\n",
      "  [0.66101695]\n",
      "  [0.50847458]]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X[:2])\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(CuDNNLSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "opt = Adam(lr=1e-3, decay=1e-5)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"D:/TextRNN/Weights/TextRNN_wgt_improv-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X, y, epochs=50, batch_size=64, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATING TEXT NOW BABYY!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = filepath = \"D:/TextRNN/Weights/TextRNN_wgt_improv-35-1.4144.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = dict((i,c) for i,c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED:\n",
      "\n",
      "\"  wings to me.\" \n",
      "\n",
      "\"there's light ahead -- i can see something moving.\" \n",
      "\n",
      "they reached the end of the  \"\n",
      "\n",
      "PREDICTIONS:\n",
      "\n",
      "door and she said them all the stairs and strpde on the door and said them a said soakl alood. \"i mean the stone on the stairs and they were a sear than they were a seacher than they were a seacher that had been a seacher that had been a seacher than they were all the seasons the seat had been a sear of the stairs and the seat had been a sear than harry had to do and started to harry and hermione and harry strpde out of the door and said them a said soakl alood. \"i mean the stone on the stairs and they were a sear than they were a seacher than they were a seacher that had been a seacher that had been a seacher than they were all the seasons the seat had been a sear of the stairs and the seat had been a sear than harry had to do and started to harry and hermione and harry strpde out of the door and said them a said soakl alood. \"i mean the stone on the stairs and they were a sear than they were a seacher than they were a seacher that had been a seacher that had been a seacher than they \n",
      " DONE!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "start = np.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"SEED:\\n\")\n",
    "print(\"\\\"\",''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "predict_len = 1000\n",
    "\n",
    "print(\"\\nPREDICTIONS:\\n\")\n",
    "for i in range(predict_len):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x/float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    print(result, end='')\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "    \n",
    "print(\"\\n DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
